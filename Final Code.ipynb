{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import collections as ct\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import pos_tag,word_tokenize\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn import naive_bayes ,svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, StratifiedKFold,train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ReadFile(inFile):\n",
    "    with open(inFile, \"r\") as f:\n",
    "        content = f.readlines()   \n",
    "    content = [x.strip() for x in content]\n",
    "    return (content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ExFeatures(df):\n",
    "    tweet = df.Body\n",
    "    df['len'] = [len(t) for t in df.Body]\n",
    "    def count_URL(tweet):\n",
    "        URL_count = 0\n",
    "        for word in tweet.split() :\n",
    "            if word.startswith('http'):\n",
    "                URL_count+=1\n",
    "        return URL_count\n",
    "    df['URL_count'] = df[\"Body\"].apply(count_URL)\n",
    "    \n",
    "    def pos_count(tweet):\n",
    "        pos_count = 0\n",
    "        for i in tweet.split():\n",
    "            if i in positive_Words:\n",
    "                pos_count+=1\n",
    "        return pos_count\n",
    "    df[\"positive_words_count\"] = df[\"Body\"].apply(pos_count)\n",
    "    \n",
    "    def neg_count(tweet):\n",
    "        neg_count = 0\n",
    "        for i in tweet.split():\n",
    "            if i in negative_Words:\n",
    "                neg_count+=1\n",
    "        return neg_count \n",
    "    df[\"negative_words_count\"] = df[\"Body\"].apply(neg_count)\n",
    "    \n",
    "    def no_of_dots(tweet):\n",
    "        liste = [val for c, val in ct.Counter(tweet).items() if c in '.' ]\n",
    "        if liste == []: liste=[0]\n",
    "        return liste[0]\n",
    "    df['no_of_dots'] = df[\"Body\"].apply(no_of_dots)\n",
    "    \n",
    "    def no_of_exclmarks(tweet):\n",
    "        return sum(1 for c in tweet if c in '!' )\n",
    "    df['no_of_exclmarks'] = df[\"Body\"].apply(no_of_exclmarks)\n",
    "    \n",
    "    def no_of_quesmarks(tweet):\n",
    "        return sum(1 for c in tweet if c in '?' )\n",
    "    df['no_of_quesmarks'] = df[\"Body\"].apply(no_of_quesmarks)\n",
    "    \n",
    "    def no_of_specialcharacters(tweet):\n",
    "        return sum(1 for c in tweet if c in '$^~*\"+=<>%&' )\n",
    "    df['no_of_specialcharacters'] = df[\"Body\"].apply(no_of_specialcharacters)\n",
    "    \n",
    "    def no_of_mentions(tweet):\n",
    "        return sum(1 for c in tweet if c in '@' )\n",
    "    df['no_of_mentions'] = df[\"Body\"].apply(no_of_mentions)\n",
    "    \n",
    "    def no_of_hashtags(tweet):\n",
    "        return sum(1 for c in tweet if c in '#' )\n",
    "    df['no_of_hashtags'] = df[\"Body\"].apply(no_of_hashtags)\n",
    "    \n",
    "    def no_of_UpperCase(tweet):\n",
    "        return sum(1 for c in tweet if c.isupper())\n",
    "    df['no_of_UpperCase'] = df[\"Body\"].apply(no_of_UpperCase)\n",
    "    \n",
    "    def number_of_quotes(tweet):\n",
    "        return sum(1 for c in tweet if c in '\"' )\n",
    "    df['number_of_quotes'] = df[\"Body\"].apply(number_of_quotes)\n",
    "    \n",
    "    def countPosEmoji(tweet):\n",
    "        numEmoji = 0\n",
    "        for x in posEmoji:\n",
    "            if (x[0] in tweet):\n",
    "                numEmoji += tweet.count(x[0])\n",
    "        return numEmoji\n",
    "    df[\"posEmoji\"] = df[\"Body\"].apply(countPosEmoji)    \n",
    "    \n",
    "    def countNegEmoji(tweet):\n",
    "        numEmoji = 0\n",
    "        for x in negEmoji:\n",
    "            if (x[0] in tweet):\n",
    "                numEmoji += tweet.count(x[0])\n",
    "        return numEmoji\n",
    "    df[\"negEmoji\"] = df[\"Body\"].apply(countNegEmoji)\n",
    "\n",
    "    def getPolarity(tweet):\n",
    "        polarity = TextBlob(tweet).sentiment.polarity\n",
    "        return polarity\n",
    "    df[\"textBlobPolarity\"] = df[\"Body\"].apply(getPolarity)\n",
    "\n",
    "    def getSubjectivity(tweet):\n",
    "        subjectivity = TextBlob(tweet).sentiment.subjectivity\n",
    "        return subjectivity\n",
    "        \n",
    "    df[\"textBlobSubjectivity\"] = df[\"Body\"].apply(getSubjectivity)   \n",
    "    \n",
    "# POS features     \n",
    "    def is_adjective(tag):\n",
    "        if tag == 'JJ' or tag == 'JJR' or tag == 'JJS':\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    def adjective_count(tweet):\n",
    "        return sum(is_adjective(i) for i in list(map(lambda x : x[1],pos_tag(tweet.split()))))\n",
    "    df[\"adjective_count\"] = df[\"Body\"].apply(adjective_count)\n",
    "\n",
    "    def is_adverb(tag):\n",
    "        if tag == 'RB' or tag == 'RBR' or tag == 'RBS':\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    def adverb_count(tweet):\n",
    "        return sum(is_adverb(i) for i in list(map(lambda x : x[1],pos_tag(tweet.split()))))\n",
    "    df[\"adverb_count\"] = df[\"Body\"].apply(adverb_count)\n",
    "\n",
    "    def is_noun(tag):\n",
    "        if tag == 'NN' or tag == 'NNS' or tag == 'NNP' or tag == 'NNPS':\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    def noun_count(tweet):\n",
    "        return sum(is_noun(i) for i in list(map(lambda x : x[1],pos_tag(tweet.split()))))\n",
    "    df[\"noun_count\"] = df[\"Body\"].apply(noun_count)\n",
    "    def is_verb(tag):\n",
    "        if tag == 'VB' or tag == 'VBD' or tag == 'VBG' or tag == 'VBN' or tag == 'VBP' or tag == 'VBZ':\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    def verb_count(tweet):\n",
    "        return sum(is_verb(i) for i in list(map(lambda x : x[1],pos_tag(tweet.split()))))\n",
    "    df[\"verb_count\"] = df[\"Body\"].apply(verb_count)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##POS sequence Extraction\n",
    "def getPOSSeq(tweet,seqlen):\n",
    "    POS = pos_tag(tweet.split())\n",
    "    results = []\n",
    "    for i in range(len(POS)-seqlen+1):\n",
    "        buffPOS = ''\n",
    "        for j in range(seqlen):\n",
    "            buffPOS += POS[i+j][1]\n",
    "        results.append(buffPOS)\n",
    "    return(results)\n",
    "\n",
    "def getTopPOSSequence(tweetslist,seqlen,n_top):\n",
    "    topNSeqs = []\n",
    "    POSdict = {'buff':0}\n",
    "    seqN = 3\n",
    "    for tweet in tweetslist:\n",
    "        seqs = getPOSSeq(tweet,seqlen)\n",
    "        for seq in seqs:\n",
    "            if seq in POSdict.keys():\n",
    "                POSdict[seq] += 1\n",
    "            else:\n",
    "                POSdict[seq] = 1\n",
    "    sortedPOSSeq = sorted(POSdict.items(), key=operator.itemgetter(1))[-100:]\n",
    "    sortedPOSSeqlist = []\n",
    "    for x in sortedPOSSeq:\n",
    "        sortedPOSSeqlist.append(x[0])\n",
    "    return sortedPOSSeqlist\n",
    "\n",
    "def POSSequenceCount(tweet,seqlen,seq):\n",
    "    num = getPOSSeq(tweet,seqlen).count(seq)\n",
    "    if(num):\n",
    "        return num\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cleaning the tweets by removing URLs, usernames (mentions) , numbers and special characters \n",
    "def clean(tweet,emoticons):\n",
    "    def Replace_unicoded(tweet):\n",
    "        soup = BeautifulSoup(tweet, 'lxml')\n",
    "        souped = soup.get_text()\n",
    "        souped = ' '.join(re.sub(\"u2019\",\"'\", souped).split())\n",
    "        souped = ' '.join(re.sub(\"u002c\",\" \", souped).split())\n",
    "        return souped\n",
    "\n",
    "    tweet = Replace_unicoded(tweet)\n",
    "    \n",
    "    def replaceEmoticons(tweet,emoticons):\n",
    "        for emotion in emoticons:\n",
    "            tweet = tweet.replace(emotion[0], \" \"+emotion[1]+\" \",100)\n",
    "        return tweet\n",
    "    tweet = replaceEmoticons(tweet,emoticons)\n",
    "    \n",
    "    def Clean_tweet1(tweet):\n",
    "        return ' '.join(re.sub(\"(\\w+:\\/\\/\\S+)|(&)|(%)|($)|(@[A-Za-z0-9_]+)|([^0-9A-Za-z_ \\t])\", \"\", tweet).split())\n",
    "    \n",
    "    tweet = Clean_tweet1(tweet)\n",
    "\n",
    "    def Remove_numbers(tweet):\n",
    "        return ' '.join(re.sub(\"(\\s?[0-9]+\\.?[0-9]*)\", \"\", tweet).split())\n",
    "    \n",
    "    tweet = Remove_numbers(tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive_Words = ReadFile('positive-words.txt')\n",
    "negative_Words = ReadFile('negative-words.txt')\n",
    "posEmoji = [x.split(',') for x in ReadFile('posEmotions.txt')]\n",
    "negEmoji = [x.split(',') for x in ReadFile('negEmotions.txt')]\n",
    "emoticons = [x.split(',') for x in ReadFile('emotions.txt')]\n",
    "positive_Words = positive_Words[35:]\n",
    "negative_Words = negative_Words[35:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>Gas by my house hit $3.39!!!! I\\u2019m going t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>Theo Walcott is still shit\\u002c watch Rafa an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>its not that I\\u2019m a GSP fan\\u002c i just h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>Iranian general says Israel\\u2019s Iron Dome c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Tehran\\u002c Mon Amour: Obama Tried to Establi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Type                                               Body\n",
       "0  positive  Gas by my house hit $3.39!!!! I\\u2019m going t...\n",
       "1  negative  Theo Walcott is still shit\\u002c watch Rafa an...\n",
       "2  negative  its not that I\\u2019m a GSP fan\\u002c i just h...\n",
       "3  negative  Iranian general says Israel\\u2019s Iron Dome c...\n",
       "4   neutral  Tehran\\u002c Mon Amour: Obama Tried to Establi..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading Dataset\n",
    "tweets = pd.read_csv(\"twitter-2015+2013train.csv\",names=['ID','Type','Body'])\n",
    "tweets = tweets[['Type','Body']]\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Body</th>\n",
       "      <th>len</th>\n",
       "      <th>URL_count</th>\n",
       "      <th>positive_words_count</th>\n",
       "      <th>negative_words_count</th>\n",
       "      <th>no_of_dots</th>\n",
       "      <th>no_of_exclmarks</th>\n",
       "      <th>no_of_quesmarks</th>\n",
       "      <th>no_of_specialcharacters</th>\n",
       "      <th>...</th>\n",
       "      <th>no_of_UpperCase</th>\n",
       "      <th>number_of_quotes</th>\n",
       "      <th>posEmoji</th>\n",
       "      <th>negEmoji</th>\n",
       "      <th>textBlobPolarity</th>\n",
       "      <th>textBlobSubjectivity</th>\n",
       "      <th>adjective_count</th>\n",
       "      <th>adverb_count</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>Gas by my house hit $3.39!!!! I\\u2019m going t...</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>Theo Walcott is still shit\\u002c watch Rafa an...</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>its not that I\\u2019m a GSP fan\\u002c i just h...</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Type                                               Body  len  \\\n",
       "0  positive  Gas by my house hit $3.39!!!! I\\u2019m going t...   70   \n",
       "1  negative  Theo Walcott is still shit\\u002c watch Rafa an...   81   \n",
       "2  negative  its not that I\\u2019m a GSP fan\\u002c i just h...   90   \n",
       "\n",
       "   URL_count  positive_words_count  negative_words_count  no_of_dots  \\\n",
       "0          0                     0                     0           2   \n",
       "1          0                     0                     0           1   \n",
       "2          0                     0                     1           2   \n",
       "\n",
       "   no_of_exclmarks  no_of_quesmarks  no_of_specialcharacters     ...      \\\n",
       "0                4                0                        1     ...       \n",
       "1                0                0                        0     ...       \n",
       "2                0                0                        0     ...       \n",
       "\n",
       "   no_of_UpperCase  number_of_quotes  posEmoji  negEmoji  textBlobPolarity  \\\n",
       "0                5                 0         1         0               0.5   \n",
       "1                5                 0         0         0               0.0   \n",
       "2                6                 0         0         0              -0.8   \n",
       "\n",
       "   textBlobSubjectivity  adjective_count  adverb_count  noun_count  verb_count  \n",
       "0                   1.0                1             0           7           2  \n",
       "1                   0.0                1             1           7           1  \n",
       "2                   0.9                0             2           8           2  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = ExFeatures(tweets)\n",
    "tweets.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Body</th>\n",
       "      <th>len</th>\n",
       "      <th>URL_count</th>\n",
       "      <th>positive_words_count</th>\n",
       "      <th>negative_words_count</th>\n",
       "      <th>no_of_dots</th>\n",
       "      <th>no_of_exclmarks</th>\n",
       "      <th>no_of_quesmarks</th>\n",
       "      <th>no_of_specialcharacters</th>\n",
       "      <th>...</th>\n",
       "      <th>no_of_UpperCase</th>\n",
       "      <th>number_of_quotes</th>\n",
       "      <th>posEmoji</th>\n",
       "      <th>negEmoji</th>\n",
       "      <th>textBlobPolarity</th>\n",
       "      <th>textBlobSubjectivity</th>\n",
       "      <th>adjective_count</th>\n",
       "      <th>adverb_count</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>Gas by my house hit Im going to Chapel Hill on...</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>Theo Walcott is still shit watch Rafa and John...</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>its not that Im a GSP fan i just hate Nick Dia...</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Type                                               Body  len  \\\n",
       "0  positive  Gas by my house hit Im going to Chapel Hill on...   70   \n",
       "1  negative  Theo Walcott is still shit watch Rafa and John...   81   \n",
       "2  negative  its not that Im a GSP fan i just hate Nick Dia...   90   \n",
       "\n",
       "   URL_count  positive_words_count  negative_words_count  no_of_dots  \\\n",
       "0          0                     0                     0           2   \n",
       "1          0                     0                     0           1   \n",
       "2          0                     0                     1           2   \n",
       "\n",
       "   no_of_exclmarks  no_of_quesmarks  no_of_specialcharacters     ...      \\\n",
       "0                4                0                        1     ...       \n",
       "1                0                0                        0     ...       \n",
       "2                0                0                        0     ...       \n",
       "\n",
       "   no_of_UpperCase  number_of_quotes  posEmoji  negEmoji  textBlobPolarity  \\\n",
       "0                5                 0         1         0               0.5   \n",
       "1                5                 0         0         0               0.0   \n",
       "2                6                 0         0         0              -0.8   \n",
       "\n",
       "   textBlobSubjectivity  adjective_count  adverb_count  noun_count  verb_count  \n",
       "0                   1.0                1             0           7           2  \n",
       "1                   0.0                1             1           7           1  \n",
       "2                   0.9                0             2           8           2  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['Body'] = tweets['Body'].apply(clean,emoticons=emoticons)\n",
    "tweets.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>tweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>218775148495515649</td>\n",
       "      <td>Musical awareness: Great Big Beautiful Tomorro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>258965201766998017</td>\n",
       "      <td>On Radio786 100.4fm 7:10 Fri Oct 19 Labour ana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID                                               Body\n",
       "0                  id                                              tweet\n",
       "1  218775148495515649  Musical awareness: Great Big Beautiful Tomorro...\n",
       "2  258965201766998017  On Radio786 100.4fm 7:10 Fri Oct 19 Labour ana..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('new_english_test.csv',names=['ID','Body'])\n",
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Body</th>\n",
       "      <th>len</th>\n",
       "      <th>URL_count</th>\n",
       "      <th>positive_words_count</th>\n",
       "      <th>negative_words_count</th>\n",
       "      <th>no_of_dots</th>\n",
       "      <th>no_of_exclmarks</th>\n",
       "      <th>no_of_quesmarks</th>\n",
       "      <th>no_of_specialcharacters</th>\n",
       "      <th>...</th>\n",
       "      <th>no_of_UpperCase</th>\n",
       "      <th>number_of_quotes</th>\n",
       "      <th>posEmoji</th>\n",
       "      <th>negEmoji</th>\n",
       "      <th>textBlobPolarity</th>\n",
       "      <th>textBlobSubjectivity</th>\n",
       "      <th>adjective_count</th>\n",
       "      <th>adverb_count</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>tweet</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>218775148495515649</td>\n",
       "      <td>Musical awareness: Great Big Beautiful Tomorro...</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4125</td>\n",
       "      <td>0.4625</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>258965201766998017</td>\n",
       "      <td>On Radio786 100.4fm 7:10 Fri Oct 19 Labour ana...</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID                                               Body  len  \\\n",
       "0                  id                                              tweet    5   \n",
       "1  218775148495515649  Musical awareness: Great Big Beautiful Tomorro...   87   \n",
       "2  258965201766998017  On Radio786 100.4fm 7:10 Fri Oct 19 Labour ana...  141   \n",
       "\n",
       "   URL_count  positive_words_count  negative_words_count  no_of_dots  \\\n",
       "0          0                     0                     0           0   \n",
       "1          0                     0                     0           0   \n",
       "2          1                     0                     1           2   \n",
       "\n",
       "   no_of_exclmarks  no_of_quesmarks  no_of_specialcharacters     ...      \\\n",
       "0                0                0                        0     ...       \n",
       "1                0                0                        0     ...       \n",
       "2                0                0                        0     ...       \n",
       "\n",
       "   no_of_UpperCase  number_of_quotes  posEmoji  negEmoji  textBlobPolarity  \\\n",
       "0                0                 0         0         0            0.0000   \n",
       "1                6                 0         0         0            0.4125   \n",
       "2                8                 0         0         0            0.0000   \n",
       "\n",
       "   textBlobSubjectivity  adjective_count  adverb_count  noun_count  verb_count  \n",
       "0                0.0000                0             0           1           0  \n",
       "1                0.4625                1             2           7           3  \n",
       "2                0.0000                0             0          13           0  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = ExFeatures(test)\n",
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Body</th>\n",
       "      <th>len</th>\n",
       "      <th>URL_count</th>\n",
       "      <th>positive_words_count</th>\n",
       "      <th>negative_words_count</th>\n",
       "      <th>no_of_dots</th>\n",
       "      <th>no_of_exclmarks</th>\n",
       "      <th>no_of_quesmarks</th>\n",
       "      <th>no_of_specialcharacters</th>\n",
       "      <th>...</th>\n",
       "      <th>no_of_UpperCase</th>\n",
       "      <th>number_of_quotes</th>\n",
       "      <th>posEmoji</th>\n",
       "      <th>negEmoji</th>\n",
       "      <th>textBlobPolarity</th>\n",
       "      <th>textBlobSubjectivity</th>\n",
       "      <th>adjective_count</th>\n",
       "      <th>adverb_count</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>tweet</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>218775148495515649</td>\n",
       "      <td>Musical awareness Great Big Beautiful Tomorrow...</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4125</td>\n",
       "      <td>0.4625</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>258965201766998017</td>\n",
       "      <td>On Radiofm Fri Oct Labour analyst Shawn Hattin...</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID                                               Body  len  \\\n",
       "0                  id                                              tweet    5   \n",
       "1  218775148495515649  Musical awareness Great Big Beautiful Tomorrow...   87   \n",
       "2  258965201766998017  On Radiofm Fri Oct Labour analyst Shawn Hattin...  141   \n",
       "\n",
       "   URL_count  positive_words_count  negative_words_count  no_of_dots  \\\n",
       "0          0                     0                     0           0   \n",
       "1          0                     0                     0           0   \n",
       "2          1                     0                     1           2   \n",
       "\n",
       "   no_of_exclmarks  no_of_quesmarks  no_of_specialcharacters     ...      \\\n",
       "0                0                0                        0     ...       \n",
       "1                0                0                        0     ...       \n",
       "2                0                0                        0     ...       \n",
       "\n",
       "   no_of_UpperCase  number_of_quotes  posEmoji  negEmoji  textBlobPolarity  \\\n",
       "0                0                 0         0         0            0.0000   \n",
       "1                6                 0         0         0            0.4125   \n",
       "2                8                 0         0         0            0.0000   \n",
       "\n",
       "   textBlobSubjectivity  adjective_count  adverb_count  noun_count  verb_count  \n",
       "0                0.0000                0             0           1           0  \n",
       "1                0.4625                1             2           7           3  \n",
       "2                0.0000                0             0          13           0  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Body'] = test['Body'].apply(clean,emoticons=emoticons)\n",
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seqlen = 4\n",
    "topPOSSequence = getTopPOSSequence(tweets['Body'].values,seqlen,100)\n",
    "for seq in topPOSSequence:    \n",
    "    tweets[seq] = tweets[\"Body\"].apply(POSSequenceCount,seqlen=seqlen,seq=seq)\n",
    "    test[seq] = test[\"Body\"].apply(POSSequenceCount,seqlen=seqlen,seq=seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10173 entries, 0 to 10172\n",
      "Columns: 10242 entries, aa to zulu\n",
      "dtypes: int64(10242)\n",
      "memory usage: 794.9 MB\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=4,max_df=0.8,ngram_range= (1,2))\n",
    "vectorized_train = vectorizer.fit_transform(tweets['Body'])\n",
    "vectorized_trainDF = pd.DataFrame(vectorized_train.toarray(),columns=vectorizer.get_feature_names())\n",
    "vectorized_trainDF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3036 entries, 0 to 3035\n",
      "Columns: 10242 entries, aa to zulu\n",
      "dtypes: int64(10242)\n",
      "memory usage: 237.2 MB\n"
     ]
    }
   ],
   "source": [
    "vectorized_test = vectorizer.transform(test['Body'])\n",
    "vectorized_testDF = pd.DataFrame(vectorized_test.toarray(),columns=vectorizer.get_feature_names())\n",
    "vectorized_testDF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>len</th>\n",
       "      <th>URL_count</th>\n",
       "      <th>positive_words_count</th>\n",
       "      <th>negative_words_count</th>\n",
       "      <th>no_of_dots</th>\n",
       "      <th>no_of_exclmarks</th>\n",
       "      <th>no_of_quesmarks</th>\n",
       "      <th>no_of_specialcharacters</th>\n",
       "      <th>no_of_mentions</th>\n",
       "      <th>...</th>\n",
       "      <th>zap</th>\n",
       "      <th>zap all</th>\n",
       "      <th>zap catch</th>\n",
       "      <th>zap nba</th>\n",
       "      <th>zimmerman</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zone</th>\n",
       "      <th>zuckerman</th>\n",
       "      <th>zulu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10464 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Type  len  URL_count  positive_words_count  negative_words_count  \\\n",
       "0  positive   70          0                     0                     0   \n",
       "1  negative   81          0                     0                     0   \n",
       "2  negative   90          0                     0                     1   \n",
       "3  negative  135          0                     1                     0   \n",
       "4   neutral  143          1                     0                     0   \n",
       "\n",
       "   no_of_dots  no_of_exclmarks  no_of_quesmarks  no_of_specialcharacters  \\\n",
       "0           2                4                0                        1   \n",
       "1           1                0                0                        0   \n",
       "2           2                0                0                        0   \n",
       "3           0                0                0                        0   \n",
       "4           1                0                0                        0   \n",
       "\n",
       "   no_of_mentions  ...   zap  zap all  zap catch  zap nba  zimmerman  zombie  \\\n",
       "0               0  ...     0        0          0        0          0       0   \n",
       "1               0  ...     0        0          0        0          0       0   \n",
       "2               0  ...     0        0          0        0          0       0   \n",
       "3               0  ...     0        0          0        0          0       0   \n",
       "4               1  ...     0        0          0        0          0       0   \n",
       "\n",
       "   zombies  zone  zuckerman  zulu  \n",
       "0        0     0          0     0  \n",
       "1        0     0          0     0  \n",
       "2        0     0          0     0  \n",
       "3        0     0          0     0  \n",
       "4        0     0          0     0  \n",
       "\n",
       "[5 rows x 10464 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_train = pd.concat([tweets['Type'],tweets.drop(['Type','Body'],axis=1) ,vectorized_trainDF],axis=1)\n",
    "final_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>len</th>\n",
       "      <th>URL_count</th>\n",
       "      <th>positive_words_count</th>\n",
       "      <th>negative_words_count</th>\n",
       "      <th>no_of_dots</th>\n",
       "      <th>no_of_exclmarks</th>\n",
       "      <th>no_of_quesmarks</th>\n",
       "      <th>no_of_specialcharacters</th>\n",
       "      <th>no_of_mentions</th>\n",
       "      <th>...</th>\n",
       "      <th>zap</th>\n",
       "      <th>zap all</th>\n",
       "      <th>zap catch</th>\n",
       "      <th>zap nba</th>\n",
       "      <th>zimmerman</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zone</th>\n",
       "      <th>zuckerman</th>\n",
       "      <th>zulu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>218775148495515649</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>258965201766998017</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>262926411352903682</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>254948834910818305</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10464 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID  len  URL_count  positive_words_count  \\\n",
       "0                  id    5          0                     0   \n",
       "1  218775148495515649   87          0                     0   \n",
       "2  258965201766998017  141          1                     0   \n",
       "3  262926411352903682  141          0                     1   \n",
       "4  254948834910818305  132          0                     0   \n",
       "\n",
       "   negative_words_count  no_of_dots  no_of_exclmarks  no_of_quesmarks  \\\n",
       "0                     0           0                0                0   \n",
       "1                     0           0                0                0   \n",
       "2                     1           2                0                0   \n",
       "3                     0           3                0                0   \n",
       "4                     0           1                0                0   \n",
       "\n",
       "   no_of_specialcharacters  no_of_mentions  ...   zap  zap all  zap catch  \\\n",
       "0                        0               0  ...     0        0          0   \n",
       "1                        0               0  ...     0        0          0   \n",
       "2                        0               0  ...     0        0          0   \n",
       "3                        0               0  ...     0        0          0   \n",
       "4                        3               2  ...     0        0          0   \n",
       "\n",
       "   zap nba  zimmerman  zombie  zombies  zone  zuckerman  zulu  \n",
       "0        0          0       0        0     0          0     0  \n",
       "1        0          0       0        0     0          0     0  \n",
       "2        0          0       0        0     0          0     0  \n",
       "3        0          0       0        0     0          0     0  \n",
       "4        0          0       0        0     0          0     0  \n",
       "\n",
       "[5 rows x 10464 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test = pd.concat([test.drop(['Body'],axis=1) ,vectorized_testDF],axis=1)\n",
    "final_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#glove2word2vec(glove_input_file=\"E:/glove.twitter.27B.200d.txt\", word2vec_output_file=\"glove_vectors.txt\")\n",
    "glove_model = KeyedVectors.load_word2vec_format(\"glove_vectors.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featureVec(words, model, num_features):\n",
    "    # Pre-initialising empty numpy array for speed\n",
    "    featureVec = np.zeros(num_features,dtype=\"float64\")\n",
    "    nwords = 0\n",
    "    \n",
    "    #Converting Index2Word which is a list to a set for better speed in the execution.\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    \n",
    "    for word in  words:\n",
    "        if word in index2word_set:\n",
    "            nwords = nwords + 1\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    \n",
    "    # Dividing the result by number of words to get average\n",
    "    featureVec = np.divide(featureVec, nwords)\n",
    "    return featureVec\n",
    "\n",
    "# Function for calculating the average feature vector\n",
    "def getAvgFeatureVecs(tweets, model, num_features):\n",
    "    counter = 0\n",
    "    tweetFeatureVecs = np.zeros((len(tweets),num_features),dtype=\"float64\")\n",
    "    for tweet in tweets:  \n",
    "        if counter%1000. == 0.:\n",
    "            print (\"Tweet %d of %d\" % (counter, len(tweets)))\n",
    "        tweetFeatureVecs[counter] = featureVec(tweet, model, num_features)\n",
    "        counter = counter+1\n",
    "        \n",
    "    return tweetFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet 0 of 10173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\be231\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:7: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "C:\\Users\\be231\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:15: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet 1000 of 10173\n",
      "Tweet 2000 of 10173\n",
      "Tweet 3000 of 10173\n",
      "Tweet 4000 of 10173\n",
      "Tweet 5000 of 10173\n",
      "Tweet 6000 of 10173\n",
      "Tweet 7000 of 10173\n",
      "Tweet 8000 of 10173\n",
      "Tweet 9000 of 10173\n",
      "Tweet 10000 of 10173\n"
     ]
    }
   ],
   "source": [
    "trainDataVecs = getAvgFeatureVecs(tweets['Body'], glove_model, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet 0 of 3036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\be231\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:7: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet 1000 of 3036\n",
      "Tweet 2000 of 3036\n",
      "Tweet 3000 of 3036\n"
     ]
    }
   ],
   "source": [
    "testDataVecs = getAvgFeatureVecs(test['Body'], glove_model, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10173, 200)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataVecsDF=pd.DataFrame(trainDataVecs,columns = ['W2vFeature %s_' %i for i in range(trainDataVecs.shape[1])])\n",
    "trainDataVecsDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3036, 200)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDataVecsDF=pd.DataFrame(testDataVecs,columns = ['W2vFeature %s_' %i for i in range(testDataVecs.shape[1])])\n",
    "testDataVecsDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AFINN_list = [x.split('\\t') for x in ReadFile('AFINN.txt')]\n",
    "def AFINN_POL(tweet):\n",
    "        AFINNN = []\n",
    "        for x in AFINN_list:\n",
    "            if(x[0] in tweet):\n",
    "                AFINNN.append(int(x[1]))\n",
    "        return sum(AFINNN)\n",
    "\n",
    "tweets[\"AFINN_Polarity\"] = tweets[\"Body\"].apply(AFINN_POL)\n",
    "test[\"AFINN_Polarity\"] = test[\"Body\"].apply(AFINN_POL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1   -6\n",
       "2    1\n",
       "3    2\n",
       "4   -2\n",
       "Name: AFINN_Polarity, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[\"AFINN_Polarity\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10173, 10465)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_w2v = pd.concat([final_train, trainDataVecsDF,tweets[\"AFINN_Polarity\"]], axis=1)\n",
    "bow_w2v = pd.concat([final_train,tweets[\"AFINN_Polarity\"]], axis=1)\n",
    "\n",
    "bow_w2v.shape\n",
    "\n",
    "#import collections\n",
    "#duplicate = [item for item, count in collections.Counter(rrrr).items() if count > 1]\n",
    "#bow_w2v.drop(duplicate,axis=1)\n",
    "#rrrr = list(bow_w2v)\n",
    "#print (len([item for item, count in collections.Counter(rrrr).items() if count > 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3036, 10465)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_w2v_test = pd.concat([final_test,testDataVecsDF,test[\"AFINN_Polarity\"]], axis=1)\n",
    "bow_w2v_test = pd.concat([final_test,test[\"AFINN_Polarity\"]], axis=1)\n",
    "\n",
    "bow_w2v_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bow_w2vcopy = bow_w2v.copy()\n",
    "bow_w2v_testcopy = bow_w2v_test.copy()\n",
    "bow_w2vcopy.fillna(0, inplace=True)\n",
    "bow_w2v_testcopy.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "clf_gs = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
    "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
    "          verbose=0, warm_start=False)\n",
    "\n",
    "#clf_gs = XGBClassifier(nthread=-1,n_estimators=201,max_depth=20,objective=\"multi:softmax\",learning_rate=.12)\n",
    "clf_gs.fit(bow_w2vcopy.drop([\"Type\",\"no_of_mentions\"],axis=1), bow_w2vcopy['Type'])\n",
    "#clf_gs.fit(final_train.drop([\"Type\",\"no_of_mentions\"],axis=1), bow_w2vcopy['Type'])\n",
    "\n",
    "#clf_gs.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = clf_gs.predict(bow_w2v_testcopy.drop([\"ID\",\"no_of_mentions\"],axis=1))\n",
    "#predicted = clf_gs.predict(final_test.drop([\"ID\",\"no_of_mentions\"],axis=1))\n",
    "predicted = predicted[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = pd.read_csv('new_english_test.csv')\n",
    "results = results.assign(sentiment=predicted)\n",
    "results.drop(['tweet'], axis=1)\n",
    "results.to_csv(path_or_buf=\"results.csv\",columns=['id','sentiment'],index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
