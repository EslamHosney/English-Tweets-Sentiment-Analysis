{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ReadFile(inFile):\n",
    "    with open(inFile, \"r\") as f:\n",
    "        content = f.readlines()   \n",
    "    content = [x.strip() for x in content]\n",
    "    return (content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "get opposite of a sentence if conbaina any negation word it check the rest of the sentence to get antonyms of the closest word\n",
    "ex. I am not so good -> will check every word after no if it has an antonym it wil replace the word and remove \"no\".\n",
    "\"\"\"\n",
    "def getAntonyms(word):\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for l in syn.lemmas():\n",
    "            if l.antonyms():\n",
    "                return (l.antonyms()[0].name())\n",
    "    return None\n",
    "\n",
    "def negateSentence(sentence):\n",
    "    negative = ['no','not','never','cannot']\n",
    "    result = []\n",
    "    wordIndex = 0\n",
    "    words = sentence.split()\n",
    "    while wordIndex < len(words):\n",
    "        stripped = words[wordIndex].strip().lower()\n",
    "        if ((stripped in negative) or re.match(r\".*n't\",stripped)):\n",
    "            for i in range(wordIndex+1,len(words)):\n",
    "                if (getAntonyms(words[i])):\n",
    "                    result.append(getAntonyms(words[i]))\n",
    "                    wordIndex = i\n",
    "                    break\n",
    "        else:\n",
    "            result.append(words[wordIndex])\n",
    "        wordIndex += 1\n",
    "    return ' '.join(result)\n",
    "\n",
    "#negate tweet\n",
    "def negateTweet(tweet):\n",
    "    #tweet = Replace_unicoded(tweet)\n",
    "    result = ''\n",
    "    delim = '; |, |\\*|\\n|\\.|\\?|\\:|!'\n",
    "    sentences = re.split(delim,tweet)\n",
    "    for sentence in sentences:\n",
    "        result += negateSentence(sentence)+'.'\n",
    "    return result\n",
    "\n",
    "def fixNegation(tweet):\n",
    "    tweet = negateTweet(tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ExFeatures(df):\n",
    "    tweet = df.Body\n",
    "    df['len'] = [len(t) for t in df.Body]\n",
    "    def count_URL(tweet):\n",
    "        URL_count = 0\n",
    "        for word in tweet.split() :\n",
    "            if word.startswith('http'):\n",
    "                URL_count+=1\n",
    "        return URL_count\n",
    "    df['URL_count'] = df[\"Body\"].apply(count_URL)\n",
    "    \n",
    "    def pos_count(tweet):\n",
    "        pos_count = 0\n",
    "        for i in tweet.split():\n",
    "            if i in positive_Words:\n",
    "                pos_count+=1\n",
    "        return pos_count\n",
    "    df[\"positive_words_count\"] = df[\"Body\"].apply(pos_count)\n",
    "    \n",
    "    def neg_count(tweet):\n",
    "        neg_count = 0\n",
    "        for i in tweet.split():\n",
    "            if i in negative_Words:\n",
    "                neg_count+=1\n",
    "        return neg_count \n",
    "    df[\"negative_words_count\"] = df[\"Body\"].apply(neg_count)\n",
    "    \n",
    "    def no_of_dots(tweet):\n",
    "        liste = [val for c, val in ct.Counter(tweet).items() if c in '.' ]\n",
    "        if liste == []: liste=[0]\n",
    "        return liste[0]\n",
    "    df['no_of_dots'] = df[\"Body\"].apply(no_of_dots)\n",
    "    \n",
    "    def no_of_exclmarks(tweet):\n",
    "        return sum(1 for c in tweet if c in '!' )\n",
    "    df['no_of_exclmarks'] = df[\"Body\"].apply(no_of_exclmarks)\n",
    "    \n",
    "    def no_of_quesmarks(tweet):\n",
    "        return sum(1 for c in tweet if c in '?' )\n",
    "    df['no_of_quesmarks'] = df[\"Body\"].apply(no_of_quesmarks)\n",
    "    \n",
    "    def no_of_specialcharacters(tweet):\n",
    "        return sum(1 for c in tweet if c in '$^~*\"+=<>%&' )\n",
    "    df['no_of_specialcharacters'] = df[\"Body\"].apply(no_of_specialcharacters)\n",
    "    \n",
    "    def no_of_mentions(tweet):\n",
    "        return sum(1 for c in tweet if c in '@' )\n",
    "    df['no_of_mentions'] = df[\"Body\"].apply(no_of_mentions)\n",
    "    \n",
    "    def no_of_hashtags(tweet):\n",
    "        return sum(1 for c in tweet if c in '#' )\n",
    "    df['no_of_hashtags'] = df[\"Body\"].apply(no_of_hashtags)\n",
    "    \n",
    "    def no_of_UpperCase(tweet):\n",
    "        return sum(1 for c in tweet if c.isupper())\n",
    "    df['no_of_UpperCase'] = df[\"Body\"].apply(no_of_UpperCase)\n",
    "    \n",
    "    def number_of_quotes(tweet):\n",
    "        return sum(1 for c in tweet if c in '\"' )\n",
    "    df['number_of_quotes'] = df[\"Body\"].apply(number_of_quotes)\n",
    "    \n",
    "    def countPosEmoji(tweet):\n",
    "        numEmoji = 0\n",
    "        for x in posEmoji:\n",
    "            if (x[0] in tweet):\n",
    "                numEmoji += tweet.count(x[0])\n",
    "        return numEmoji\n",
    "    df[\"posEmoji\"] = df[\"Body\"].apply(countPosEmoji)    \n",
    "    \n",
    "    def countNegEmoji(tweet):\n",
    "        numEmoji = 0\n",
    "        for x in negEmoji:\n",
    "            if (x[0] in tweet):\n",
    "                numEmoji += tweet.count(x[0])\n",
    "        return numEmoji\n",
    "    df[\"negEmoji\"] = df[\"Body\"].apply(countNegEmoji)\n",
    "\n",
    "    def getPolarity(tweet):\n",
    "        polarity = TextBlob(tweet).sentiment.polarity\n",
    "        return polarity\n",
    "    df[\"textBlobPolarity\"] = df[\"Body\"].apply(getPolarity)\n",
    "\n",
    "    def getSubjectivity(tweet):\n",
    "        subjectivity = TextBlob(tweet).sentiment.subjectivity\n",
    "        return subjectivity\n",
    "        \n",
    "    df[\"textBlobSubjectivity\"] = df[\"Body\"].apply(getSubjectivity)   \n",
    "    \n",
    "# POS features     \n",
    "    def is_adjective(tag):\n",
    "        if tag == 'JJ' or tag == 'JJR' or tag == 'JJS':\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    def adjective_count(tweet):\n",
    "        return sum(is_adjective(i) for i in list(map(lambda x : x[1],pos_tag(tweet.split()))))\n",
    "    df[\"adjective_count\"] = df[\"Body\"].apply(adjective_count)\n",
    "\n",
    "    def is_adverb(tag):\n",
    "        if tag == 'RB' or tag == 'RBR' or tag == 'RBS':\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    def adverb_count(tweet):\n",
    "        return sum(is_adverb(i) for i in list(map(lambda x : x[1],pos_tag(tweet.split()))))\n",
    "    df[\"adverb_count\"] = df[\"Body\"].apply(adverb_count)\n",
    "\n",
    "    def is_noun(tag):\n",
    "        if tag == 'NN' or tag == 'NNS' or tag == 'NNP' or tag == 'NNPS':\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    def noun_count(tweet):\n",
    "        return sum(is_noun(i) for i in list(map(lambda x : x[1],pos_tag(tweet.split()))))\n",
    "    df[\"noun_count\"] = df[\"Body\"].apply(noun_count)\n",
    "    def is_verb(tag):\n",
    "        if tag == 'VB' or tag == 'VBD' or tag == 'VBG' or tag == 'VBN' or tag == 'VBP' or tag == 'VBZ':\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    def verb_count(tweet):\n",
    "        return sum(is_verb(i) for i in list(map(lambda x : x[1],pos_tag(tweet.split()))))\n",
    "    df[\"verb_count\"] = df[\"Body\"].apply(verb_count)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##POS sequence Extraction\n",
    "def getPOSSeq(tweet,seqlen):\n",
    "    POS = pos_tag(tweet.split())\n",
    "    results = []\n",
    "    for i in range(len(POS)-seqlen+1):\n",
    "        buffPOS = ''\n",
    "        for j in range(seqlen):\n",
    "            buffPOS += POS[i+j][1]\n",
    "        results.append(buffPOS)\n",
    "    return(results)\n",
    "\n",
    "def getTopPOSSequence(tweetslist,seqlen,n_top):\n",
    "    topNSeqs = []\n",
    "    POSdict = {'buff':0}\n",
    "    seqN = 3\n",
    "    for tweet in tweetslist:\n",
    "        seqs = getPOSSeq(tweet,seqlen)\n",
    "        for seq in seqs:\n",
    "            if seq in POSdict.keys():\n",
    "                POSdict[seq] += 1\n",
    "            else:\n",
    "                POSdict[seq] = 1\n",
    "    sortedPOSSeq = sorted(POSdict.items(), key=operator.itemgetter(1))[-100:]\n",
    "    sortedPOSSeqlist = []\n",
    "    for x in sortedPOSSeq:\n",
    "        sortedPOSSeqlist.append(x[0])\n",
    "    return sortedPOSSeqlist\n",
    "\n",
    "def POSSequenceCount(tweet,seqlen,seq):\n",
    "    num = getPOSSeq(tweet,seqlen).count(seq)\n",
    "    if(num):\n",
    "        return num\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cleaning the tweets by removing URLs, usernames (mentions) , numbers and special characters \n",
    "def clean(tweet,emoticons):\n",
    "    def Replace_unicoded(tweet):\n",
    "        soup = BeautifulSoup(tweet, 'lxml')\n",
    "        souped = soup.get_text()\n",
    "        souped = ' '.join(re.sub(\"u2019\",\"'\", souped).split())\n",
    "        souped = ' '.join(re.sub(\"u002c\",\" \", souped).split())\n",
    "        return souped\n",
    "\n",
    "    tweet = Replace_unicoded(tweet)\n",
    "    \n",
    "    def replaceEmoticons(tweet,emoticons):\n",
    "        for emotion in emoticons:\n",
    "            tweet = tweet.replace(emotion[0], \" \"+emotion[1]+\" \",100)\n",
    "        return tweet\n",
    "    tweet = replaceEmoticons(tweet,emoticons)\n",
    "    \n",
    "    def Clean_tweet1(tweet):\n",
    "        return ' '.join(re.sub(\"(\\w+:\\/\\/\\S+)|(&)|(%)|($)|(@[A-Za-z0-9_]+)|([^0-9A-Za-z_ \\t])\", \"\", tweet).split())\n",
    "    \n",
    "    tweet = Clean_tweet1(tweet)\n",
    "\n",
    "    def Remove_numbers(tweet):\n",
    "        return ' '.join(re.sub(\"(\\s?[0-9]+\\.?[0-9]*)\", \"\", tweet).split())\n",
    "    \n",
    "    tweet = Remove_numbers(tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive_Words = ReadFile('positive-words.txt')\n",
    "negative_Words = ReadFile('negative-words.txt')\n",
    "posEmoji = [x.split(',') for x in ReadFile('posEmotions.txt')]\n",
    "negEmoji = [x.split(',') for x in ReadFile('negEmotions.txt')]\n",
    "emoticons = [x.split(',') for x in ReadFile('emotions.txt')]\n",
    "positive_Words = positive_Words[35:]\n",
    "negative_Words = negative_Words[35:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>Gas by my house hit $3.39!!!! I\\u2019m going t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>Theo Walcott is still shit\\u002c watch Rafa an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>its not that I\\u2019m a GSP fan\\u002c i just h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>Iranian general says Israel\\u2019s Iron Dome c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Tehran\\u002c Mon Amour: Obama Tried to Establi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Type                                               Body\n",
       "0  positive  Gas by my house hit $3.39!!!! I\\u2019m going t...\n",
       "1  negative  Theo Walcott is still shit\\u002c watch Rafa an...\n",
       "2  negative  its not that I\\u2019m a GSP fan\\u002c i just h...\n",
       "3  negative  Iranian general says Israel\\u2019s Iron Dome c...\n",
       "4   neutral  Tehran\\u002c Mon Amour: Obama Tried to Establi..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading Dataset\n",
    "tweets = pd.read_csv(\"twitter-2015+2013train.csv\",names=['ID','Type','Body'])\n",
    "tweets = tweets[['Type','Body']]\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Body</th>\n",
       "      <th>len</th>\n",
       "      <th>URL_count</th>\n",
       "      <th>positive_words_count</th>\n",
       "      <th>negative_words_count</th>\n",
       "      <th>no_of_dots</th>\n",
       "      <th>no_of_exclmarks</th>\n",
       "      <th>no_of_quesmarks</th>\n",
       "      <th>no_of_specialcharacters</th>\n",
       "      <th>...</th>\n",
       "      <th>no_of_UpperCase</th>\n",
       "      <th>number_of_quotes</th>\n",
       "      <th>posEmoji</th>\n",
       "      <th>negEmoji</th>\n",
       "      <th>textBlobPolarity</th>\n",
       "      <th>textBlobSubjectivity</th>\n",
       "      <th>adjective_count</th>\n",
       "      <th>adverb_count</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>Gas by my house hit $3.39!!!! I\\u2019m going t...</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>Theo Walcott is still shit\\u002c watch Rafa an...</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>its not that I\\u2019m a GSP fan\\u002c i just h...</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Type                                               Body  len  \\\n",
       "0  positive  Gas by my house hit $3.39!!!! I\\u2019m going t...   70   \n",
       "1  negative  Theo Walcott is still shit\\u002c watch Rafa an...   81   \n",
       "2  negative  its not that I\\u2019m a GSP fan\\u002c i just h...   90   \n",
       "\n",
       "   URL_count  positive_words_count  negative_words_count  no_of_dots  \\\n",
       "0          0                     0                     0           2   \n",
       "1          0                     0                     0           1   \n",
       "2          0                     0                     1           2   \n",
       "\n",
       "   no_of_exclmarks  no_of_quesmarks  no_of_specialcharacters     ...      \\\n",
       "0                4                0                        1     ...       \n",
       "1                0                0                        0     ...       \n",
       "2                0                0                        0     ...       \n",
       "\n",
       "   no_of_UpperCase  number_of_quotes  posEmoji  negEmoji  textBlobPolarity  \\\n",
       "0                5                 0         1         0               0.5   \n",
       "1                5                 0         0         0               0.0   \n",
       "2                6                 0         0         0              -0.8   \n",
       "\n",
       "   textBlobSubjectivity  adjective_count  adverb_count  noun_count  verb_count  \n",
       "0                   1.0                1             0           7           2  \n",
       "1                   0.0                1             1           7           1  \n",
       "2                   0.9                0             2           8           2  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = ExFeatures(tweets)\n",
    "tweets.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Body</th>\n",
       "      <th>len</th>\n",
       "      <th>URL_count</th>\n",
       "      <th>positive_words_count</th>\n",
       "      <th>negative_words_count</th>\n",
       "      <th>no_of_dots</th>\n",
       "      <th>no_of_exclmarks</th>\n",
       "      <th>no_of_quesmarks</th>\n",
       "      <th>no_of_specialcharacters</th>\n",
       "      <th>...</th>\n",
       "      <th>no_of_UpperCase</th>\n",
       "      <th>number_of_quotes</th>\n",
       "      <th>posEmoji</th>\n",
       "      <th>negEmoji</th>\n",
       "      <th>textBlobPolarity</th>\n",
       "      <th>textBlobSubjectivity</th>\n",
       "      <th>adjective_count</th>\n",
       "      <th>adverb_count</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>Gas by my house hit Im going to Chapel Hill on...</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>Theo Walcott is still shit watch Rafa and John...</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>its not that Im a GSP fan i just hate Nick Dia...</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Type                                               Body  len  \\\n",
       "0  positive  Gas by my house hit Im going to Chapel Hill on...   70   \n",
       "1  negative  Theo Walcott is still shit watch Rafa and John...   81   \n",
       "2  negative  its not that Im a GSP fan i just hate Nick Dia...   90   \n",
       "\n",
       "   URL_count  positive_words_count  negative_words_count  no_of_dots  \\\n",
       "0          0                     0                     0           2   \n",
       "1          0                     0                     0           1   \n",
       "2          0                     0                     1           2   \n",
       "\n",
       "   no_of_exclmarks  no_of_quesmarks  no_of_specialcharacters     ...      \\\n",
       "0                4                0                        1     ...       \n",
       "1                0                0                        0     ...       \n",
       "2                0                0                        0     ...       \n",
       "\n",
       "   no_of_UpperCase  number_of_quotes  posEmoji  negEmoji  textBlobPolarity  \\\n",
       "0                5                 0         1         0               0.5   \n",
       "1                5                 0         0         0               0.0   \n",
       "2                6                 0         0         0              -0.8   \n",
       "\n",
       "   textBlobSubjectivity  adjective_count  adverb_count  noun_count  verb_count  \n",
       "0                   1.0                1             0           7           2  \n",
       "1                   0.0                1             1           7           1  \n",
       "2                   0.9                0             2           8           2  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['Body'] = tweets['Body'].apply(clean,emoticons=emoticons)\n",
    "tweets.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>tweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>218775148495515649</td>\n",
       "      <td>Musical awareness: Great Big Beautiful Tomorro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>258965201766998017</td>\n",
       "      <td>On Radio786 100.4fm 7:10 Fri Oct 19 Labour ana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID                                               Body\n",
       "0                  id                                              tweet\n",
       "1  218775148495515649  Musical awareness: Great Big Beautiful Tomorro...\n",
       "2  258965201766998017  On Radio786 100.4fm 7:10 Fri Oct 19 Labour ana..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('new_english_test.csv',names=['ID','Body'])\n",
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Body</th>\n",
       "      <th>len</th>\n",
       "      <th>URL_count</th>\n",
       "      <th>positive_words_count</th>\n",
       "      <th>negative_words_count</th>\n",
       "      <th>no_of_dots</th>\n",
       "      <th>no_of_exclmarks</th>\n",
       "      <th>no_of_quesmarks</th>\n",
       "      <th>no_of_specialcharacters</th>\n",
       "      <th>...</th>\n",
       "      <th>no_of_UpperCase</th>\n",
       "      <th>number_of_quotes</th>\n",
       "      <th>posEmoji</th>\n",
       "      <th>negEmoji</th>\n",
       "      <th>textBlobPolarity</th>\n",
       "      <th>textBlobSubjectivity</th>\n",
       "      <th>adjective_count</th>\n",
       "      <th>adverb_count</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>tweet</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>218775148495515649</td>\n",
       "      <td>Musical awareness: Great Big Beautiful Tomorro...</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4125</td>\n",
       "      <td>0.4625</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>258965201766998017</td>\n",
       "      <td>On Radio786 100.4fm 7:10 Fri Oct 19 Labour ana...</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID                                               Body  len  \\\n",
       "0                  id                                              tweet    5   \n",
       "1  218775148495515649  Musical awareness: Great Big Beautiful Tomorro...   87   \n",
       "2  258965201766998017  On Radio786 100.4fm 7:10 Fri Oct 19 Labour ana...  141   \n",
       "\n",
       "   URL_count  positive_words_count  negative_words_count  no_of_dots  \\\n",
       "0          0                     0                     0           0   \n",
       "1          0                     0                     0           0   \n",
       "2          1                     0                     1           2   \n",
       "\n",
       "   no_of_exclmarks  no_of_quesmarks  no_of_specialcharacters     ...      \\\n",
       "0                0                0                        0     ...       \n",
       "1                0                0                        0     ...       \n",
       "2                0                0                        0     ...       \n",
       "\n",
       "   no_of_UpperCase  number_of_quotes  posEmoji  negEmoji  textBlobPolarity  \\\n",
       "0                0                 0         0         0            0.0000   \n",
       "1                6                 0         0         0            0.4125   \n",
       "2                8                 0         0         0            0.0000   \n",
       "\n",
       "   textBlobSubjectivity  adjective_count  adverb_count  noun_count  verb_count  \n",
       "0                0.0000                0             0           1           0  \n",
       "1                0.4625                1             2           7           3  \n",
       "2                0.0000                0             0          13           0  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = ExFeatures(test)\n",
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Body</th>\n",
       "      <th>len</th>\n",
       "      <th>URL_count</th>\n",
       "      <th>positive_words_count</th>\n",
       "      <th>negative_words_count</th>\n",
       "      <th>no_of_dots</th>\n",
       "      <th>no_of_exclmarks</th>\n",
       "      <th>no_of_quesmarks</th>\n",
       "      <th>no_of_specialcharacters</th>\n",
       "      <th>...</th>\n",
       "      <th>no_of_UpperCase</th>\n",
       "      <th>number_of_quotes</th>\n",
       "      <th>posEmoji</th>\n",
       "      <th>negEmoji</th>\n",
       "      <th>textBlobPolarity</th>\n",
       "      <th>textBlobSubjectivity</th>\n",
       "      <th>adjective_count</th>\n",
       "      <th>adverb_count</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>tweet</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>218775148495515649</td>\n",
       "      <td>Musical awareness Great Big Beautiful Tomorrow...</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4125</td>\n",
       "      <td>0.4625</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>258965201766998017</td>\n",
       "      <td>On Radiofm Fri Oct Labour analyst Shawn Hattin...</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID                                               Body  len  \\\n",
       "0                  id                                              tweet    5   \n",
       "1  218775148495515649  Musical awareness Great Big Beautiful Tomorrow...   87   \n",
       "2  258965201766998017  On Radiofm Fri Oct Labour analyst Shawn Hattin...  141   \n",
       "\n",
       "   URL_count  positive_words_count  negative_words_count  no_of_dots  \\\n",
       "0          0                     0                     0           0   \n",
       "1          0                     0                     0           0   \n",
       "2          1                     0                     1           2   \n",
       "\n",
       "   no_of_exclmarks  no_of_quesmarks  no_of_specialcharacters     ...      \\\n",
       "0                0                0                        0     ...       \n",
       "1                0                0                        0     ...       \n",
       "2                0                0                        0     ...       \n",
       "\n",
       "   no_of_UpperCase  number_of_quotes  posEmoji  negEmoji  textBlobPolarity  \\\n",
       "0                0                 0         0         0            0.0000   \n",
       "1                6                 0         0         0            0.4125   \n",
       "2                8                 0         0         0            0.0000   \n",
       "\n",
       "   textBlobSubjectivity  adjective_count  adverb_count  noun_count  verb_count  \n",
       "0                0.0000                0             0           1           0  \n",
       "1                0.4625                1             2           7           3  \n",
       "2                0.0000                0             0          13           0  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Body'] = test['Body'].apply(clean,emoticons=emoticons)\n",
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seqlen = 2\n",
    "topPOSSequence = getTopPOSSequence(tweets['Body'].values,seqlen,100)\n",
    "for seq in topPOSSequence:    \n",
    "    tweets[seq] = tweets[\"Body\"].apply(POSSequenceCount,seqlen=seqlen,seq=seq)\n",
    "    test[seq] = test[\"Body\"].apply(POSSequenceCount,seqlen=seqlen,seq=seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10173 entries, 0 to 10172\n",
      "Columns: 10242 entries, aa to zulu\n",
      "dtypes: int64(10242)\n",
      "memory usage: 794.9 MB\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=4,max_df=0.8,ngram_range= (1,2))\n",
    "vectorized_train = vectorizer.fit_transform(tweets['Body'])\n",
    "vectorized_trainDF = pd.DataFrame(vectorized_train.toarray(),columns=vectorizer.get_feature_names())\n",
    "vectorized_trainDF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3036 entries, 0 to 3035\n",
      "Columns: 10242 entries, aa to zulu\n",
      "dtypes: int64(10242)\n",
      "memory usage: 237.2 MB\n"
     ]
    }
   ],
   "source": [
    "vectorized_test = vectorizer.transform(test['Body'])\n",
    "vectorized_testDF = pd.DataFrame(vectorized_test.toarray(),columns=vectorizer.get_feature_names())\n",
    "vectorized_testDF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>len</th>\n",
       "      <th>URL_count</th>\n",
       "      <th>positive_words_count</th>\n",
       "      <th>negative_words_count</th>\n",
       "      <th>no_of_dots</th>\n",
       "      <th>no_of_exclmarks</th>\n",
       "      <th>no_of_quesmarks</th>\n",
       "      <th>no_of_specialcharacters</th>\n",
       "      <th>no_of_mentions</th>\n",
       "      <th>...</th>\n",
       "      <th>zap</th>\n",
       "      <th>zap all</th>\n",
       "      <th>zap catch</th>\n",
       "      <th>zap nba</th>\n",
       "      <th>zimmerman</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zone</th>\n",
       "      <th>zuckerman</th>\n",
       "      <th>zulu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10363 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Type  len  URL_count  positive_words_count  negative_words_count  \\\n",
       "0  positive   70          0                     0                     0   \n",
       "1  negative   81          0                     0                     0   \n",
       "2  negative   90          0                     0                     1   \n",
       "3  negative  135          0                     1                     0   \n",
       "4   neutral  143          1                     0                     0   \n",
       "\n",
       "   no_of_dots  no_of_exclmarks  no_of_quesmarks  no_of_specialcharacters  \\\n",
       "0           2                4                0                        1   \n",
       "1           1                0                0                        0   \n",
       "2           2                0                0                        0   \n",
       "3           0                0                0                        0   \n",
       "4           1                0                0                        0   \n",
       "\n",
       "   no_of_mentions  ...   zap  zap all  zap catch  zap nba  zimmerman  zombie  \\\n",
       "0               0  ...     0        0          0        0          0       0   \n",
       "1               0  ...     0        0          0        0          0       0   \n",
       "2               0  ...     0        0          0        0          0       0   \n",
       "3               0  ...     0        0          0        0          0       0   \n",
       "4               1  ...     0        0          0        0          0       0   \n",
       "\n",
       "   zombies  zone  zuckerman  zulu  \n",
       "0        0     0          0     0  \n",
       "1        0     0          0     0  \n",
       "2        0     0          0     0  \n",
       "3        0     0          0     0  \n",
       "4        0     0          0     0  \n",
       "\n",
       "[5 rows x 10363 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_train = pd.concat([tweets['Type'],tweets.drop(['Type','Body'],axis=1) ,vectorized_trainDF],axis=1)\n",
    "final_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>len</th>\n",
       "      <th>URL_count</th>\n",
       "      <th>positive_words_count</th>\n",
       "      <th>negative_words_count</th>\n",
       "      <th>no_of_dots</th>\n",
       "      <th>no_of_exclmarks</th>\n",
       "      <th>no_of_quesmarks</th>\n",
       "      <th>no_of_specialcharacters</th>\n",
       "      <th>no_of_mentions</th>\n",
       "      <th>...</th>\n",
       "      <th>zap</th>\n",
       "      <th>zap all</th>\n",
       "      <th>zap catch</th>\n",
       "      <th>zap nba</th>\n",
       "      <th>zimmerman</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zone</th>\n",
       "      <th>zuckerman</th>\n",
       "      <th>zulu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>218775148495515649</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>258965201766998017</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>262926411352903682</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>254948834910818305</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10363 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID  len  URL_count  positive_words_count  \\\n",
       "0                  id    5          0                     0   \n",
       "1  218775148495515649   87          0                     0   \n",
       "2  258965201766998017  141          1                     0   \n",
       "3  262926411352903682  141          0                     1   \n",
       "4  254948834910818305  132          0                     0   \n",
       "\n",
       "   negative_words_count  no_of_dots  no_of_exclmarks  no_of_quesmarks  \\\n",
       "0                     0           0                0                0   \n",
       "1                     0           0                0                0   \n",
       "2                     1           2                0                0   \n",
       "3                     0           3                0                0   \n",
       "4                     0           1                0                0   \n",
       "\n",
       "   no_of_specialcharacters  no_of_mentions  ...   zap  zap all  zap catch  \\\n",
       "0                        0               0  ...     0        0          0   \n",
       "1                        0               0  ...     0        0          0   \n",
       "2                        0               0  ...     0        0          0   \n",
       "3                        0               0  ...     0        0          0   \n",
       "4                        3               2  ...     0        0          0   \n",
       "\n",
       "   zap nba  zimmerman  zombie  zombies  zone  zuckerman  zulu  \n",
       "0        0          0       0        0     0          0     0  \n",
       "1        0          0       0        0     0          0     0  \n",
       "2        0          0       0        0     0          0     0  \n",
       "3        0          0       0        0     0          0     0  \n",
       "4        0          0       0        0     0          0     0  \n",
       "\n",
       "[5 rows x 10363 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test = pd.concat([test.drop(['Body'],axis=1) ,vectorized_testDF],axis=1)\n",
    "final_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#glove2word2vec(glove_input_file=\"E:/glove.twitter.27B.200d.txt\", word2vec_output_file=\"glove_vectors.txt\")\n",
    "glove_model = KeyedVectors.load_word2vec_format(\"glove_vectors.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featureVec(words, model, num_features):\n",
    "    # Pre-initialising empty numpy array for speed\n",
    "    featureVec = np.zeros(num_features,dtype=\"float64\")\n",
    "    nwords = 0\n",
    "    \n",
    "    #Converting Index2Word which is a list to a set for better speed in the execution.\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    \n",
    "    for word in  words:\n",
    "        if word in index2word_set:\n",
    "            nwords = nwords + 1\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    \n",
    "    # Dividing the result by number of words to get average\n",
    "    featureVec = np.divide(featureVec, nwords)\n",
    "    return featureVec\n",
    "\n",
    "# Function for calculating the average feature vector\n",
    "def getAvgFeatureVecs(tweets, model, num_features):\n",
    "    counter = 0\n",
    "    tweetFeatureVecs = np.zeros((len(tweets),num_features),dtype=\"float64\")\n",
    "    for tweet in tweets:  \n",
    "        if counter%1000. == 0.:\n",
    "            print (\"Tweet %d of %d\" % (counter, len(tweets)))\n",
    "        tweetFeatureVecs[counter] = featureVec(tweet, model, num_features)\n",
    "        counter = counter+1\n",
    "        \n",
    "    return tweetFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet 0 of 10173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\be231\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:7: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "C:\\Users\\be231\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:15: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet 1000 of 10173\n",
      "Tweet 2000 of 10173\n",
      "Tweet 3000 of 10173\n",
      "Tweet 4000 of 10173\n",
      "Tweet 5000 of 10173\n",
      "Tweet 6000 of 10173\n",
      "Tweet 7000 of 10173\n",
      "Tweet 8000 of 10173\n",
      "Tweet 9000 of 10173\n",
      "Tweet 10000 of 10173\n"
     ]
    }
   ],
   "source": [
    "trainDataVecs = getAvgFeatureVecs(tweets['Body'], glove_model, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet 0 of 3036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\be231\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:7: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet 1000 of 3036\n",
      "Tweet 2000 of 3036\n",
      "Tweet 3000 of 3036\n"
     ]
    }
   ],
   "source": [
    "testDataVecs = getAvgFeatureVecs(test['Body'], glove_model, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10173, 200)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataVecsDF=pd.DataFrame(trainDataVecs,columns = ['W2vFeature %s_' %i for i in range(trainDataVecs.shape[1])])\n",
    "trainDataVecsDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3036, 200)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDataVecsDF=pd.DataFrame(testDataVecs,columns = ['W2vFeature %s_' %i for i in range(testDataVecs.shape[1])])\n",
    "testDataVecsDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "bow_w2v = pd.concat([final_train, trainDataVecsDF], axis=1)\n",
    "bow_w2v.shape\n",
    "\n",
    "#import collections\n",
    "#duplicate = [item for item, count in collections.Counter(rrrr).items() if count > 1]\n",
    "#bow_w2v.drop(duplicate,axis=1)\n",
    "#rrrr = list(bow_w2v)\n",
    "#print (len([item for item, count in collections.Counter(rrrr).items() if count > 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3036, 10563)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_w2v_test = pd.concat([final_test,testDataVecsDF], axis=1)\n",
    "bow_w2v_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bow_w2vcopy = bow_w2v.copy()\n",
    "bow_w2v_testcopy = bow_w2v_test.copy()\n",
    "bow_w2vcopy.fillna(0, inplace=True)\n",
    "bow_w2v_testcopy.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#XGBoost Grid search\n",
    "tweets_train = final_train.drop([\"Type\"],axis=1)\n",
    "train_labels = final_train['Type']\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipe = Pipeline([('classifier', XGBClassifier())])\n",
    "search_space = [{'classifier': [XGBClassifier()],\n",
    "                 'classifier__nthread': [-1],\n",
    "                 'classifier__n_estimators': [103,201, 403],\n",
    "                 'classifier__max_depth': [3,10,15, 30],\n",
    "                 'classifier__objective': [\"multi:softmax\",\"binary:logistic\"],\n",
    "                 'classifier__learning_rate': [0.05, 0.1, 0.15, 0.3]}]\n",
    "\n",
    "\n",
    "clf_gss = GridSearchCV(pipe, search_space, cv=5, verbose=0)\n",
    "\n",
    "best_model = clf_gss.fit(final_train.drop([\"Type\"],axis=1), final_train['Type'])\n",
    "\n",
    "# View best model\n",
    "print (best_model.best_estimator_.get_params()['classifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "pipe = Pipeline([('classifier', RandomForestClassifier())])\n",
    "search_space = [{'classifier': [RandomForestClassifier()],\n",
    "                 'classifier__n_estimators': [10, 100, 1000],\n",
    "                 'classifier__max_features': [1, 2, 3]}]\n",
    "               \n",
    "\n",
    "clf_gss = GridSearchCV(pipe, search_space, cv=5, verbose=0)\n",
    "\n",
    "best_model = clf_gss.fit(final_train.drop([\"Type\"],axis=1), final_train['Type'])\n",
    "\n",
    "# View best model\n",
    "print (best_model.best_estimator_.get_params()['classifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Classifiers trails\n",
    "clfrKnearest = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "clfrKnearest.fit(tweets_train,train_labels)\n",
    "predictedK = clfr.predict(tweets_val)\n",
    "acc = metrics.accuracy_score(val_labels,predictedK) \n",
    "print('accuracy = ',acc*100,'%')\n",
    "\n",
    "clfrNaive = naive_bayes.MultinomialNB()\n",
    "clfrNaive.fit(tweets_train,train_labels)\n",
    "predictedNaive = clfr.predict(tweets_val)\n",
    "acc = metrics.accuracy_score(val_labels,predictedNaive)\n",
    "print('accuracy = ',acc*100,'%')\n",
    "\n",
    "for i in range(len(val_labels)):\n",
    "    print (val_labels[i],predictedNaive[i],predictedXGB[i])\n",
    "acc = metrics.accuracy_score(val_labels,predicted)  \n",
    "print('accuracy = ',acc*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.12, max_delta_step=0,\n",
       "       max_depth=20, min_child_weight=1, missing=None, n_estimators=201,\n",
       "       n_jobs=1, nthread=-1, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_gs = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
    "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
    "          verbose=0, warm_start=False)\n",
    "\n",
    "clf_gs = XGBClassifier(nthread=-1,n_estimators=201,max_depth=20,objective=\"multi:softmax\",learning_rate=.12)\n",
    "clf_gs.fit(bow_w2vcopy.drop([\"Type\"],axis=1), bow_w2vcopy['Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    positive\n",
       "1    negative\n",
       "2    negative\n",
       "3    negative\n",
       "4     neutral\n",
       "Name: Type, dtype: object"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_w2vcopy['Type'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>len</th>\n",
       "      <th>URL_count</th>\n",
       "      <th>positive_words_count</th>\n",
       "      <th>negative_words_count</th>\n",
       "      <th>no_of_dots</th>\n",
       "      <th>no_of_exclmarks</th>\n",
       "      <th>no_of_quesmarks</th>\n",
       "      <th>no_of_specialcharacters</th>\n",
       "      <th>no_of_mentions</th>\n",
       "      <th>...</th>\n",
       "      <th>W2vFeature 190_</th>\n",
       "      <th>W2vFeature 191_</th>\n",
       "      <th>W2vFeature 192_</th>\n",
       "      <th>W2vFeature 193_</th>\n",
       "      <th>W2vFeature 194_</th>\n",
       "      <th>W2vFeature 195_</th>\n",
       "      <th>W2vFeature 196_</th>\n",
       "      <th>W2vFeature 197_</th>\n",
       "      <th>W2vFeature 198_</th>\n",
       "      <th>W2vFeature 199_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.070661</td>\n",
       "      <td>0.377460</td>\n",
       "      <td>-0.579102</td>\n",
       "      <td>0.296534</td>\n",
       "      <td>-0.099056</td>\n",
       "      <td>0.135564</td>\n",
       "      <td>0.030092</td>\n",
       "      <td>-0.263439</td>\n",
       "      <td>0.034199</td>\n",
       "      <td>-0.031498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>218775148495515649</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.177638</td>\n",
       "      <td>0.240933</td>\n",
       "      <td>-0.166556</td>\n",
       "      <td>0.216743</td>\n",
       "      <td>-0.061036</td>\n",
       "      <td>0.097181</td>\n",
       "      <td>-0.108041</td>\n",
       "      <td>-0.370387</td>\n",
       "      <td>0.190655</td>\n",
       "      <td>0.089424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>258965201766998017</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.135459</td>\n",
       "      <td>0.225265</td>\n",
       "      <td>-0.154029</td>\n",
       "      <td>0.163532</td>\n",
       "      <td>-0.097447</td>\n",
       "      <td>0.072990</td>\n",
       "      <td>-0.142078</td>\n",
       "      <td>-0.415543</td>\n",
       "      <td>0.156611</td>\n",
       "      <td>0.135041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>262926411352903682</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.135555</td>\n",
       "      <td>0.204452</td>\n",
       "      <td>-0.138231</td>\n",
       "      <td>0.239701</td>\n",
       "      <td>-0.057297</td>\n",
       "      <td>0.037440</td>\n",
       "      <td>-0.106794</td>\n",
       "      <td>-0.405302</td>\n",
       "      <td>0.187243</td>\n",
       "      <td>0.113300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>254948834910818305</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100995</td>\n",
       "      <td>0.239441</td>\n",
       "      <td>-0.167882</td>\n",
       "      <td>0.224557</td>\n",
       "      <td>-0.017336</td>\n",
       "      <td>0.045128</td>\n",
       "      <td>-0.105315</td>\n",
       "      <td>-0.407548</td>\n",
       "      <td>0.186473</td>\n",
       "      <td>0.125416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10563 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID  len  URL_count  positive_words_count  \\\n",
       "0                  id    5          0                     0   \n",
       "1  218775148495515649   87          0                     0   \n",
       "2  258965201766998017  141          1                     0   \n",
       "3  262926411352903682  141          0                     1   \n",
       "4  254948834910818305  132          0                     0   \n",
       "\n",
       "   negative_words_count  no_of_dots  no_of_exclmarks  no_of_quesmarks  \\\n",
       "0                     0           0                0                0   \n",
       "1                     0           0                0                0   \n",
       "2                     1           2                0                0   \n",
       "3                     0           3                0                0   \n",
       "4                     0           1                0                0   \n",
       "\n",
       "   no_of_specialcharacters  no_of_mentions       ...         W2vFeature 190_  \\\n",
       "0                        0               0       ...               -0.070661   \n",
       "1                        0               0       ...               -0.177638   \n",
       "2                        0               0       ...               -0.135459   \n",
       "3                        0               0       ...               -0.135555   \n",
       "4                        3               2       ...               -0.100995   \n",
       "\n",
       "   W2vFeature 191_  W2vFeature 192_  W2vFeature 193_  W2vFeature 194_  \\\n",
       "0         0.377460        -0.579102         0.296534        -0.099056   \n",
       "1         0.240933        -0.166556         0.216743        -0.061036   \n",
       "2         0.225265        -0.154029         0.163532        -0.097447   \n",
       "3         0.204452        -0.138231         0.239701        -0.057297   \n",
       "4         0.239441        -0.167882         0.224557        -0.017336   \n",
       "\n",
       "   W2vFeature 195_  W2vFeature 196_  W2vFeature 197_  W2vFeature 198_  \\\n",
       "0         0.135564         0.030092        -0.263439         0.034199   \n",
       "1         0.097181        -0.108041        -0.370387         0.190655   \n",
       "2         0.072990        -0.142078        -0.415543         0.156611   \n",
       "3         0.037440        -0.106794        -0.405302         0.187243   \n",
       "4         0.045128        -0.105315        -0.407548         0.186473   \n",
       "\n",
       "   W2vFeature 199_  \n",
       "0        -0.031498  \n",
       "1         0.089424  \n",
       "2         0.135041  \n",
       "3         0.113300  \n",
       "4         0.125416  \n",
       "\n",
       "[5 rows x 10563 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_w2v_testcopy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = clf_gs.predict(bow_w2v_testcopy.drop([\"ID\"],axis=1))\n",
    "predicted = predicted[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = pd.read_csv('new_english_test.csv')\n",
    "results = results.assign(sentiment=predicted)\n",
    "results.drop(['tweet'], axis=1)\n",
    "results.to_csv(path_or_buf=\"test.csv\",columns=['id','sentiment'],index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
